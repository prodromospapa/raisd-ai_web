import os
import stdpopsim as sps
import subprocess
from tqdm import tqdm
import shutil
import argparse
import time
import json
from datetime import datetime

# default thread count (safe when os.cpu_count() returns None)
# CLI: accept species as stdpopsim id or full name (e.g. 'HomSap' or 'Homo sapiens')
parser = argparse.ArgumentParser(description="Train RAiSD-AI models for a species")
parser.add_argument("--species", type=str, required=True,
                    help="Species id (stdpopsim short id) or full name, e.g. 'HomSap' or 'Homo sapiens'.")
parser.add_argument("--train-sample-individuals", type=int, default=100,
                    help="Individuals per simulation (default 100)")
parser.add_argument("--train-replicates", type=int, default=1000,
                    help="Number of replicates per model (default 1000)")
parser.add_argument("--sel-s", type=float, default=0.1,
                    help="Selection coefficient used for sweep sims (default 0.1)")
parser.add_argument("--window", type=int, default=500,
                    help="Window size used to choose target SNPs (default 500)")
parser.add_argument("--ips", type=int, default=11,
                    help="ips parameter for RAiSD image generation (default 11)")
parser.add_argument("--iws", type=int, default=10,
                    help="iws parameter for RAiSD image generation (default 10)")
parser.add_argument("--epochs", type=int, default=3,
                    help="Training epochs for RAiSD-AI (default 3)")
parser.add_argument("--gpu", action='store_true', default=False,
                    help="Enable GPU mode for simulator/training when supported")
parser.add_argument("--parallel", type=int, default=None,
                    help="Parallel worker count for simulator runs (default: half of CPUs)")
parser.add_argument("--engine", type=str, default="msms",
                    help="Simulation engine to use (default: msms)")
args = parser.parse_args()

species = args.species
train_sample_individuals = args.train_sample_individuals
train_replicates = args.train_replicates
sel_s = args.sel_s

window = args.window
ips = args.ips
iws = args.iws
epochs = args.epochs
gpu = args.gpu
# compute a safe default for parallel if not provided
if args.parallel is None:
    parallel = max(1, (os.cpu_count() or 2) // 2)
else:
    parallel = args.parallel
engine = args.engine


def run_subprocess(args, cwd, desc):
    """Run a subprocess, capture output, exit script on failure with detailed message."""
    # Run the subprocess and return CompletedProcess on success.
    # On CalledProcessError raise the exception to allow callers to decide retry/recording.
    try:
        return subprocess.run(
            args,
            cwd=cwd,
            check=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
        )
    except subprocess.CalledProcessError as e:
        # Print a compact error message for immediate visibility, then re-raise
        print(
            f"\n===== SUBPROCESS ERROR: {desc} =====\n"
            f"Command: {' '.join(args)}\n"
            f"Return code: {getattr(e, 'returncode', 'N/A')}\n"
            f"STDOUT:\n{getattr(e, 'stdout', '(empty)') or '(empty)'}\n"
            f"STDERR:\n{getattr(e, 'stderr', '(empty)') or '(empty)'}\n"
            f"===================================\n"
        )
        raise


def record_failed(key, reason, source="1.train"):
    """Append a failure record to data/{species_folder_name}/failed_parts.jsonl"""
    failed_dir = os.path.join("data", species_folder_name)
    os.makedirs(failed_dir, exist_ok=True)
    failed_path = os.path.join(failed_dir, "failed_parts.jsonl")
    record = {
        "key": key,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "reason": reason,
        "source": source,
    }
    try:
        with open(failed_path, "a", encoding="utf-8") as fh:
            fh.write(json.dumps(record, ensure_ascii=False) + "\n")
    except Exception:
        # If recording fails, at least print to stderr so user can take action
        print(f"Failed to write failed_parts entry for {key}: {reason}")


def run_simulation(engine,species_id,model_id,population,train_sample_individuals,window,ips,iws,chromosome,train_replicates,sel_s):
    # build target run directory: current_path/data/species_folder_name/model_id/population/chromosome
    out_dir = os.path.join(os.getcwd(), "data", species_folder_name, str(model_id), str(population), str(chromosome))
    os.makedirs(out_dir, exist_ok=True)
    args = [
        "simulator.py",
        "--engine", str(engine),
        "--species-id", str(species_id),
        "--model-id", str(model_id),
        "--pop-order", str(population),
        "--sample-individuals", str(train_sample_individuals),
        "--target-snps", str(int(window + ((ips/2) * iws)*1.1)),
        "--chromosome", str(chromosome),
        "--replicates", str(train_replicates),
        "--output", "sweep.ms",
        "--sweep-pos", "50",
        "--fixation-time", "0",
        "--sel-s", str(sel_s),
        "--parallel", str(parallel),
        "--target-snps-tol", "10",
    "--paired-neutral", "neutral.ms",
        ]
    if gpu:
        args.append("--gpu")
    # run inside the target directory; if it fails, retry once using discoal and add --sweep-time (in generations)
    try:
        run_subprocess(args, out_dir, f"simulation {model_id}/{population}/{chromosome}")
    except subprocess.CalledProcessError:
        # prepare alternative args: switch engine to discoal and add sweep-time arg (only for this run)
        alt_args = args.copy()
        if "--engine" in alt_args:
            idx = alt_args.index("--engine")
            if idx + 1 < len(alt_args):
                alt_args[idx + 1] = "discoal"
        else:
            alt_args.extend(["--engine", "discoal"])

        if "--sweep-time" not in alt_args:
            # Previous scripts passed 0.01 in 4N units; simulator.py now expects generations ago.
            # Assuming a typical N0 ~ 10,000, 0.01 (4N units) â‰ˆ 0.01 * 4 * 10000 = 400 generations.
            # Use 400 generations as a conservative fallback for the retry.
            alt_args.extend(["--sweep-time", "400"])

        try:
            run_subprocess(alt_args, out_dir, f"simulation {model_id}/{population}/{chromosome} (discoal retry)")
            print(f"Engine '{engine}' failed for {model_id}/{population}/{chromosome}; retry succeeded with 'discoal' and --sweep-time.")
        except subprocess.CalledProcessError:
            # Let caller handle recording the failure
            raise

def get_info(model_id,population,chromosome):
    out_dir = os.path.join(os.getcwd(), "data", species_folder_name, str(model_id), str(population), str(chromosome))
    params = {}
    selection = {}
    try:
        with open(f"{out_dir}/sweep.ms", 'r') as f:
            for i in range(4):
                line = f.readline()
                if not line:
                    break
                if i == 2:
                    params = {k: __import__('ast').literal_eval(v.strip().capitalize() if v.strip().lower() in ('true','false') else v.strip()) for k, v in (item.split('=', 1) for item in line.replace("# params: ", "").strip().split(", ") if "=" in item)}
                if i == 3:
                    selection = {k: __import__('ast').literal_eval(v.strip().capitalize() if v.strip().lower() in ('true','false') else v.strip()) for k, v in (item.split('=', 1) for item in line.replace("# selection: ", "").strip().split(", ") if "=" in item)}
    except FileNotFoundError:
        print(f"Info file not found: {out_dir}/sweep.ms")

    return params, selection

def ms2bin(model_id,pop_order,window,ips,iws,chromosome,type_,sweep_pos,length):
    out_dir = os.path.join(os.getcwd(), "data", species_folder_name, str(model_id), str(pop_order), str(chromosome))
    args = [
        "RAiSD-AI",
        "-n", "bin",
        "-I", f"{type_}.ms",
        "-w", str(window),
        "-ips", str(ips),
        "-iws", str(iws),
        "-its", str(sweep_pos),
        "-op", "IMG-GEN",
        "-icl", f"{type_}TR",
        "-bin",
        "-typ", "1",
        "-L", str(length),
        "-f"
    ]

    run_subprocess(args, out_dir, f"RAiSD IMG-GEN {model_id}/{pop_order}/{chromosome}/{type_}")
    # remove temporary files only after success
    tmp_ms = f"{out_dir}/{type_}.ms"
    if os.path.exists(tmp_ms):
        os.remove(tmp_ms)
    info_file = f"{out_dir}/RAiSD_Info.bin.{type_}TR"
    if os.path.exists(info_file):
        os.remove(info_file)


def train_model(model_id, pop_order, chromosome, epochs):
    out_dir = os.path.join(os.getcwd(), "data", species_folder_name, str(model_id), str(pop_order), str(chromosome))
    args = [
        "RAiSD-AI",
        "-n", "model",
        "-I", "RAiSD_Images.bin",
        "-f", 
        "-op", "MDL-GEN",
        "-e", str(epochs),
        "-arc", "FASTER-NN"
    ]
    run_subprocess(args, out_dir, f"model training {model_id}/{pop_order}/{chromosome}")

species_dict = {sp.name: sp.id for sp in sps.all_species()}
if species in species_dict.values():
    species_full_name = [sp.name for sp in sps.all_species() if sp.id == species][0]
else:
    species_full_name = species
species_folder_name = "".join(c if c.isalnum() or c in "-_ " else "_" for c in str(species_full_name)).strip().replace(" ", "_")
os.makedirs(os.path.join("data", species_folder_name), exist_ok=True)

# shared failed parts file (JSON-lines, used by 3.sfs.py)
skipped_file = os.path.join("data", species_folder_name, "failed_parts.jsonl")

def load_skipped():
    skipped = set()
    try:
        if os.path.exists(skipped_file):
            with open(skipped_file, 'r', encoding='utf-8') as rf:
                for line in rf:
                    try:
                        obj = json.loads(line)
                        key = obj.get('key')
                        if key:
                            skipped.add(key)
                    except Exception:
                        # ignore malformed lines
                        continue
    except Exception:
        pass
    return skipped
existing_skipped = load_skipped()

if species in species_dict.keys():
    species_id = species_dict[species]
elif species in species_dict.values():
    species_id = species
else:
    raise ValueError(f"Unknown species: {species}")

species_std = sps.get_species(species_id)

if not os.path.exists(f"data/{species_folder_name}/chromosomes.txt"):
        chromosomes = [c.id for c in species_std.genome.chromosomes]
        remove_chr = input(f"Which of {chromosomes} to remove (comma-separated): ")
        remove_chr = [c.strip() for c in remove_chr.split(",") if c.strip()]
        chromosomes = [c for c in chromosomes if c not in remove_chr]
        with open(f"data/{species_folder_name}/chromosomes.txt", 'w') as f:
            for chromosome in chromosomes:
                f.write(chromosome+"\n")
else:
    with open(f"data/{species_folder_name}/chromosomes.txt", 'r') as f:
        chromosomes = [line.strip() for line in f]

demographic_models = {
        m.id: [p.name for p in species_std.get_demographic_model(m.id).populations]
        for m in species_std.demographic_models}

# Progress accounting (models with varying population counts) -----------------
total_tasks = sum(len(pops) * len(chromosomes) for pops in demographic_models.values())

# Count already completed tasks (model file exists)
def _model_done(model_id, population, chromosome):
    return os.path.exists(f"data/{species_folder_name}/{model_id}/{population}/{chromosome}/RAiSD_Model.model/model.pt")

tasks_done = sum(
    1
    for model_id, pops in demographic_models.items()
    for population in pops
    for chromosome in chromosomes
    if _model_done(model_id, population, chromosome)
)

first = True
with tqdm(total=total_tasks, initial=tasks_done, desc="total", unit="task") as total_bar:
    for model_id, populations in demographic_models.items():
        for population in populations:
            for chromosome in chromosomes:
                key = f"{model_id}={population}"
                # refresh skipped set on each iteration to catch skips written by other processes
                try:
                    latest_skipped = load_skipped()
                    # any newly recorded skipped keys should be removed from sfs.csv to keep bookkeeping consistent
                    # update the in-memory set (we no longer modify sfs.csv here)
                    existing_skipped.update(latest_skipped)
                except Exception:
                    # if we fail to reload skipped file, fall back to previously loaded set
                    pass

                if key in existing_skipped:
                    total_bar.update(1)
                    total_bar.refresh()
                    # canonical skip list contains this key; no additional skip logging required
                    continue

                if _model_done(model_id, population, chromosome):
                    total_bar.update(1)
                    total_bar.refresh()
                    first = False
                    # already counted in initial; just continue
                    continue
                try:
                    if first:
                        pass
                    first = False
                    sweep_path = f"data/{species_folder_name}/{model_id}/{population}/{chromosome}/sweep.ms"
                    neutral_path = f"data/{species_folder_name}/{model_id}/{population}/{chromosome}/neutral.ms"
                    if not os.path.exists(sweep_path) or not os.path.exists(neutral_path):
                        try:
                            run_simulation(engine, species_id, model_id, population, train_sample_individuals, window, ips, iws, chromosome, train_replicates, sel_s)
                        except subprocess.CalledProcessError as e:
                            reason = f"simulation_error {getattr(e, 'returncode', 'N/A')}"
                            # include a snippet of stderr if available
                            try:
                                stderr = getattr(e, 'stderr', '') or ''
                                if stderr:
                                    reason += f": {stderr.strip()[:200]}"
                            except Exception:
                                pass
                            # record failure and skip further processing for this key
                            record_failed(key, reason, source="1.train")
                            existing_skipped.add(key)
                            continue

                    for type_ in ["sweep", "neutral"]:
                        try:
                            if type_ == "sweep":
                                params, selection = get_info(model_id, population, chromosome)
                                sweep_bp = selection.get("sweep_bp")
                                length = params.get("length")
                                with open(f"data/{species_folder_name}/{model_id}/{population}/{chromosome}/sweep_info.txt", 'w') as f:
                                    f.write(f"sweep_bp: {sweep_bp}\nlength: {length}\n")
                            else:
                                with open(f"data/{species_folder_name}/{model_id}/{population}/{chromosome}/sweep_info.txt", 'r') as f:
                                    lines = f.readlines()
                                    sweep_bp = int(lines[0].strip().split(": ")[1])
                                    length = int(lines[1].strip().split(": ")[1])

                            img_info = f"data/{species_folder_name}/{model_id}/{population}/{chromosome}/RAiSD_Images.bin/{type_}TR"
                            if not os.path.exists(img_info):
                                try:
                                    ms2bin(model_id, population, window, ips, iws, chromosome, type_, sweep_bp, length)
                                except subprocess.CalledProcessError as e:
                                    reason = f"ms2bin_error {getattr(e, 'returncode', 'N/A')}"
                                    try:
                                        stderr = getattr(e, 'stderr', '') or ''
                                        if stderr:
                                            reason += f": {stderr.strip()[:200]}"
                                    except Exception:
                                        pass
                                    record_failed(key, reason, source="1.train")
                                    existing_skipped.add(key)
                                    raise
                            if type_ == "neutral":
                                os.remove(f"data/{species_folder_name}/{model_id}/{population}/{chromosome}/sweep_info.txt")
                        except Exception:
                            # If any per-type processing fails, ensure we break out to outer loop
                            break

                    # If we reached here without adding the key to skipped, proceed to training
                    if key in existing_skipped:
                        # already recorded as failed by earlier step
                        continue

                    try:
                        train_model(model_id, population, chromosome, epochs)
                    except subprocess.CalledProcessError as e:
                        reason = f"training_error {getattr(e, 'returncode', 'N/A')}"
                        try:
                            stderr = getattr(e, 'stderr', '') or ''
                            if stderr:
                                reason += f": {stderr.strip()[:200]}"
                        except Exception:
                            pass
                        record_failed(key, reason, source="1.train")
                        existing_skipped.add(key)
                        continue

                    img_bin = f"data/{species_folder_name}/{model_id}/{population}/{chromosome}/RAiSD_Images.bin"
                    if os.path.exists(img_bin):
                        shutil.rmtree(img_bin)
                finally:
                    # Only advance when task just completed (not pre-counted)
                    total_bar.update(1)
                    total_bar.refresh()